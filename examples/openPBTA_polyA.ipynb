{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is code from RF_deploy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_checker(input_file):\n",
    "    '''\n",
    "    Function checks the input file's genes.\n",
    "    The intersection between the input file's genes and the predetermined classifier genes is taken.\n",
    "    Then the function checks for genes are not present in the input file.\n",
    "    For those genes, the expression vector is set to 0.\n",
    "    A new dataframe is returned with the correct order of genes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file; pandas df - shape should be (samples x genes)\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    new_input_file; pandas df - shape (samples x genes)\n",
    "    '''\n",
    "    \n",
    "    classifier_genes = np.loadtxt('../ClassifierGenes.txt', dtype='str')\n",
    "    new_input_file = input_file.T.loc[classifier_genes].T # seleting classifier selected genes in the classifier determined order\n",
    "    \n",
    "    # will fill genes that do not exist in the input with zero\n",
    "    # if no NAN values, none will be filled\n",
    "    new_input_file = new_input_file.fillna(0) \n",
    "    \n",
    "    return new_input_file\n",
    "\n",
    "def deploy(input_file):\n",
    "    classifier_genes = np.loadtxt('../ClassifierGenes.txt', dtype='str')\n",
    "\n",
    "    expr_input = input_file\n",
    "    \n",
    "    print('reading input...') \n",
    "    expr_input = pd.read_csv(expr_input, sep='\\t', index_col=0)\n",
    "\n",
    "    print(\"before gene intersection...\")\n",
    "    print(expr_input.shape)\n",
    "    expr_input = gene_checker(expr_input) # making sure genes are correct for classifier\n",
    "    print(\"After gene intersection...\")\n",
    "    print(expr_input.shape)\n",
    "\n",
    "    print('applying model...')\n",
    "    model = pickle.load(open('../RiboVsPoly.sav', 'rb'))\n",
    "    print(model)\n",
    "    \n",
    "    predictions = model.predict(expr_input)\n",
    "    predict_proba = model.predict_proba(expr_input)\n",
    "    \n",
    "    print(\"saving results...\")\n",
    "    predictions = pd.DataFrame(np.hstack([predictions.reshape(-1,1), predict_proba]), index=expr_input.index, columns=['Ribo', 'Proba_0', 'Proba_1'])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying on openPBTA polyA samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading input...\n",
      "before gene intersection...\n",
      "(58, 58347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After gene intersection...\n",
      "(58, 25924)\n",
      "applying model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=None, class_weight=None,\n",
      "                       criterion='gini', max_depth=5, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=-1, oob_score=True, random_state=42, verbose=1,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done 420 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=15)]: Done 770 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=15)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=15)]: Done 420 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done 770 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=15)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = deploy(\"../data/pbta-gene-expression-rsem-tpm.polya.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ribo</th>\n",
       "      <th>Proba_0</th>\n",
       "      <th>Proba_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BS_0VXZCRJS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622000</td>\n",
       "      <td>0.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_0ZA67BBC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654994</td>\n",
       "      <td>0.345006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_1N7MQZGR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_21ET39G7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668994</td>\n",
       "      <td>0.331006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_2JP7RBMB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_3AC3SRWH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737054</td>\n",
       "      <td>0.262946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_49CJNZ06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658994</td>\n",
       "      <td>0.341006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_4PPHAQXF</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_4PWDGEB0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_58YXHGAJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_5VPM0F36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666994</td>\n",
       "      <td>0.333006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_68KX6A42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609994</td>\n",
       "      <td>0.390006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_6M2053M0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669994</td>\n",
       "      <td>0.330006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_685DACMS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_7WM3MNZ0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.335006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_8ZY4GST0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_BMMY0H73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_BYCX6VK1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_C83TK159</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_EZ3147MX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590994</td>\n",
       "      <td>0.409006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_F0JB4EAK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.309006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_FCDAH728</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640994</td>\n",
       "      <td>0.359006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_G3NN392N</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794999</td>\n",
       "      <td>0.205001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_GWSJ4Z9H</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_H97S5SQN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_HWGWYCY7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651994</td>\n",
       "      <td>0.348006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_JB43XBCQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682994</td>\n",
       "      <td>0.317006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_JQVAWTTM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.269006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_KBEX4RT2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_JGA9BP3A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_NB9XXBW6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>0.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_NEVYM2FP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645994</td>\n",
       "      <td>0.354006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_NGSG2KB6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700994</td>\n",
       "      <td>0.299006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_NPA6CZQF</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_PS0P3QJ3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719994</td>\n",
       "      <td>0.280006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_PXCPK5XS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_QNNX91SM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652994</td>\n",
       "      <td>0.347006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_R7NTZR4C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_R9B92M75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624994</td>\n",
       "      <td>0.375006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_RX1YTZ7F</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629994</td>\n",
       "      <td>0.370006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_SNVM7CZT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_T3DGY9J9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_QKT3TJVK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635994</td>\n",
       "      <td>0.364006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_W1385R8Y</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639994</td>\n",
       "      <td>0.360006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_W4H1D4Y6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_W7MFJZ5A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661994</td>\n",
       "      <td>0.338006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_X0XXN9BK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.348000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_X4DD4KSZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596000</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_XGDPK33A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633000</td>\n",
       "      <td>0.367000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_XM1AHBDJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806994</td>\n",
       "      <td>0.193006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_XZM79E42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679994</td>\n",
       "      <td>0.320006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_YDEVMD24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674000</td>\n",
       "      <td>0.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_Z3RCA1T9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614994</td>\n",
       "      <td>0.385006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_ZD5HN296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_ZF6BSFNF</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701994</td>\n",
       "      <td>0.298006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_ZQ76ZBEX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677994</td>\n",
       "      <td>0.322006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_ZQKGJD70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.327006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BS_S6Q7NKA3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.356000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ribo   Proba_0   Proba_1\n",
       "BS_0VXZCRJS   0.0  0.622000  0.378000\n",
       "BS_0ZA67BBC   0.0  0.654994  0.345006\n",
       "BS_1N7MQZGR   0.0  0.645000  0.355000\n",
       "BS_21ET39G7   0.0  0.668994  0.331006\n",
       "BS_2JP7RBMB   0.0  0.660000  0.340000\n",
       "BS_3AC3SRWH   0.0  0.737054  0.262946\n",
       "BS_49CJNZ06   0.0  0.658994  0.341006\n",
       "BS_4PPHAQXF   0.0  0.664000  0.336000\n",
       "BS_4PWDGEB0   0.0  0.665000  0.335000\n",
       "BS_58YXHGAJ   0.0  0.653000  0.347000\n",
       "BS_5VPM0F36   0.0  0.666994  0.333006\n",
       "BS_68KX6A42   0.0  0.609994  0.390006\n",
       "BS_6M2053M0   0.0  0.669994  0.330006\n",
       "BS_685DACMS   0.0  0.660000  0.340000\n",
       "BS_7WM3MNZ0   0.0  0.664994  0.335006\n",
       "BS_8ZY4GST0   0.0  0.636000  0.364000\n",
       "BS_BMMY0H73   0.0  0.642000  0.358000\n",
       "BS_BYCX6VK1   0.0  0.627000  0.373000\n",
       "BS_C83TK159   0.0  0.638000  0.362000\n",
       "BS_EZ3147MX   0.0  0.590994  0.409006\n",
       "BS_F0JB4EAK   0.0  0.690994  0.309006\n",
       "BS_FCDAH728   0.0  0.640994  0.359006\n",
       "BS_G3NN392N   0.0  0.794999  0.205001\n",
       "BS_GWSJ4Z9H   0.0  0.616000  0.384000\n",
       "BS_H97S5SQN   0.0  0.629000  0.371000\n",
       "BS_HWGWYCY7   0.0  0.651994  0.348006\n",
       "BS_JB43XBCQ   0.0  0.682994  0.317006\n",
       "BS_JQVAWTTM   0.0  0.730994  0.269006\n",
       "BS_KBEX4RT2   0.0  0.642000  0.358000\n",
       "BS_JGA9BP3A   0.0  0.655000  0.345000\n",
       "BS_NB9XXBW6   0.0  0.672000  0.328000\n",
       "BS_NEVYM2FP   0.0  0.645994  0.354006\n",
       "BS_NGSG2KB6   0.0  0.700994  0.299006\n",
       "BS_NPA6CZQF   0.0  0.670000  0.330000\n",
       "BS_PS0P3QJ3   0.0  0.719994  0.280006\n",
       "BS_PXCPK5XS   0.0  0.598000  0.402000\n",
       "BS_QNNX91SM   0.0  0.652994  0.347006\n",
       "BS_R7NTZR4C   0.0  0.650000  0.350000\n",
       "BS_R9B92M75   0.0  0.624994  0.375006\n",
       "BS_RX1YTZ7F   0.0  0.629994  0.370006\n",
       "BS_SNVM7CZT   0.0  0.671000  0.329000\n",
       "BS_T3DGY9J9   0.0  0.664000  0.336000\n",
       "BS_QKT3TJVK   0.0  0.635994  0.364006\n",
       "BS_W1385R8Y   0.0  0.639994  0.360006\n",
       "BS_W4H1D4Y6   0.0  0.599000  0.401000\n",
       "BS_W7MFJZ5A   0.0  0.661994  0.338006\n",
       "BS_X0XXN9BK   0.0  0.652000  0.348000\n",
       "BS_X4DD4KSZ   0.0  0.596000  0.404000\n",
       "BS_XGDPK33A   0.0  0.633000  0.367000\n",
       "BS_XM1AHBDJ   0.0  0.806994  0.193006\n",
       "BS_XZM79E42   0.0  0.679994  0.320006\n",
       "BS_YDEVMD24   0.0  0.674000  0.326000\n",
       "BS_Z3RCA1T9   0.0  0.614994  0.385006\n",
       "BS_ZD5HN296   0.0  0.654000  0.346000\n",
       "BS_ZF6BSFNF   0.0  0.701994  0.298006\n",
       "BS_ZQ76ZBEX   0.0  0.677994  0.322006\n",
       "BS_ZQKGJD70   0.0  0.672994  0.327006\n",
       "BS_S6Q7NKA3   0.0  0.644000  0.356000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All samples were predicted to be polyA\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
